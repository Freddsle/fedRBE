{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "from classes.client import Client\n",
    "from classes.coordinator_utils import select_common_features_variables, \\\n",
    "    compute_beta, reorder_matrix, create_beta_mask\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Functions ###\n",
    "### Just run this, these functions are needed in various places ###\n",
    "\n",
    "### Define the client class ###\n",
    "class ClientWrapper:\n",
    "    \"\"\"\n",
    "    Holds all information necessary for the simulation run to work.\n",
    "    Defines the input data of the client, it's name and if it should be\n",
    "    considered as the coordinator\n",
    "    \"\"\"\n",
    "    def __init__(self, id: str, input_folder: str, coordinator: bool = False):\n",
    "        self.id = id\n",
    "        self.input_folder = input_folder\n",
    "        self.is_coordinator = coordinator\n",
    "        self.client_class = None\n",
    "\n",
    "def _check_consistency_clientwrappers(clientWrappers: List[ClientWrapper]) -> None:\n",
    "    \"\"\"\n",
    "    Checks for a list of clients if they were created correctly\n",
    "    Raises a ValueError in case of inconsistencies\n",
    "    Checks:\n",
    "        1. If exactly one coordinator exists\n",
    "    \"\"\"\n",
    "    coord = False\n",
    "    for clientWrapper in clientWrappers:\n",
    "        if coord and clientWrapper.is_coordinator:\n",
    "            raise ValueError(\"More than one coordinator was defined, please check \"+\\\n",
    "                            \"the code defining the clients\")\n",
    "        if clientWrapper.is_coordinator:\n",
    "            coord = True\n",
    "    if not coord:\n",
    "        raise ValueError(\"No client instance is a coordinator, please designate \"+\\\n",
    "                        \"any client as a coordinator\")\n",
    "    \n",
    "def _compare_central_federated_dfs(name:str,\n",
    "                                   central_df: pd.DataFrame,\n",
    "                                   federated_df: pd.DataFrame,\n",
    "                                   intersection_features: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Compares two dataframes for equality. First checks that index and columns\n",
    "    are the same, then analyses the element wise differences.\n",
    "    See the analyse_diff_df function for more details on the difference analysis.\n",
    "    If both dataframes contain a NaN value at the same position, this is considered\n",
    "    as equal (0 as difference).\n",
    "    Args:\n",
    "        name: Name used for printing\n",
    "        central_df: The central dataframe\n",
    "        federated_df: The federated dataframe\n",
    "        intersection_features: The features that are common to both dataframes\n",
    "    \"\"\"\n",
    "    central_df = central_df.sort_index(axis=0).sort_index(axis=1)\n",
    "    federated_df = federated_df.sort_index(axis=0).sort_index(axis=1)\n",
    "    print(f\"_________________________Analysing: {name}_________________________\")\n",
    "    ### compare columns and index ###\n",
    "    failed = False\n",
    "    if not central_df.columns.equals(federated_df.columns):\n",
    "        print(f\"Columns do not match for central_df and federated_df\")\n",
    "        union_cols = central_df.columns.union(federated_df.columns)\n",
    "        intercept_cols = central_df.columns.intersection(federated_df.columns)\n",
    "        print(f\"Union-Intercept of columns: {union_cols.difference(intercept_cols)}\")\n",
    "        failed = True\n",
    "    if not central_df.index.equals(federated_df.index):\n",
    "        print(f\"Rows do not match for central_df and federated_df\")\n",
    "        union_rows = central_df.index.union(federated_df.index)\n",
    "        intercept_rows = central_df.index.intersection(federated_df.index)\n",
    "        print(f\"Union-Intercept of rows: {union_rows.difference(intercept_rows)}\")\n",
    "        failed = True\n",
    "    if failed:\n",
    "        print(f\"_________________________FAILED: {name}_________________________\")\n",
    "\n",
    "    df_diff = (central_df - federated_df).abs()\n",
    "    print(f\"Max difference: {df_diff.max().max()}\")\n",
    "    print(f\"Mean difference: {df_diff.mean().mean()}\")\n",
    "    print(f\"Max diff at position: {df_diff.idxmax().idxmax()}\")\n",
    "\n",
    "    df_diff_intersect = df_diff.loc[intersection_features]\n",
    "    print(f\"Max difference in intersect: {df_diff_intersect.max().max()}\")\n",
    "    print(f\"Mean difference in intersect: {df_diff_intersect.mean().mean()}\")\n",
    "    print(f\"Max diff at position in intersect: {df_diff_intersect.idxmax().idxmax()}\")\n",
    "\n",
    "def _concat_federated_results(clientWrappers: List[ClientWrapper],\n",
    "                              samples_in_columns=True) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Concatenates the results of the federated clients into one dataframe\n",
    "    Also checks which features are common to all clients\n",
    "    and returns them\n",
    "    Args:\n",
    "        clientWrappers: List of ClientWrapper instances, containing the data\n",
    "            in the data_corrected attribute\n",
    "        samples_in_columns: If True, the samples are in the columns, if False\n",
    "            they are in the rows. For expression files this is true.\n",
    "            This decides how to aggregate the dataframes\n",
    "    Returns:\n",
    "        merged_df: The merged dataframe containing the data of all clients\n",
    "        intersection_features: The features that are common to all clients\n",
    "    \"\"\"\n",
    "    merged_df = None\n",
    "    intersection_features = set()\n",
    "    for clientWrapper in clientWrappers:\n",
    "        # get the data in the correct format\n",
    "        if not hasattr(clientWrapper, \"data_corrected\") or \\\n",
    "            clientWrapper.data_corrected is None:\n",
    "            raise ValueError(\"No data was found in the clientWrappers\")\n",
    "        corrected_data = clientWrapper.data_corrected\n",
    "        if not samples_in_columns:\n",
    "            corrected_data = corrected_data.T\n",
    "\n",
    "        cleaned_corrected_features = set(corrected_data.dropna().index)\n",
    "        # initialize the merged_df\n",
    "        if merged_df is None:\n",
    "            merged_df = corrected_data\n",
    "            intersection_features = cleaned_corrected_features\n",
    "            continue\n",
    "\n",
    "        # merge the data\n",
    "        merged_df = pd.concat([merged_df, corrected_data], axis=1)\n",
    "        intersection_features = intersection_features.intersection(cleaned_corrected_features)\n",
    "\n",
    "    # final check\n",
    "    if merged_df is None:\n",
    "        raise ValueError(\"No data was found in the clientWrappers\")\n",
    "    # reverse the Transpose if necessary\n",
    "    if not samples_in_columns:\n",
    "        merged_df = merged_df.T\n",
    "    return merged_df, list(intersection_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This part defines the data used. A ClientWrapper class is used to      ###\n",
    "### describe all cohorts. If other data should be tested, this part should ###\n",
    "### be changed                                                             ###\n",
    "### Define the different clients ###\n",
    "    # we use a helper class for each client, see the helper function\n",
    "    # code block or the later definitions here for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Microarray Data ####################\n",
    "# First define the basefolder where all files are located\n",
    "base_dir = os.path.join(\"..\")\n",
    "# Go back to the git repos root dir\n",
    "base_dir = os.path.join(base_dir, \"evaluation_data\", \"microarray\", \"before\")\n",
    "\n",
    "# List of cohort names\n",
    "cohort_names = [\n",
    "    'GSE38666',  # Client 1 (Coordinator)\n",
    "    'GSE14407',  # Client 2\n",
    "    'GSE6008',   # Client 3\n",
    "    'GSE40595',  # Client 4\n",
    "    'GSE26712',  # Client 5\n",
    "    'GSE69428',  # Client 6\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################### Proteomics Data ####################\n",
    "\n",
    "# # First define the basefolder where all files are located\n",
    "# base_dir = os.path.join(\"..\")\n",
    "# # Go back to the git repos root dir\n",
    "# base_dir = os.path.join(base_dir, \"evaluation_data\", \"proteomics\", \"before\")\n",
    "\n",
    "# # List of cohort names\n",
    "# cohort_names = [\n",
    "#     'lab_A',  # Client 1 (Coordinator)\n",
    "#     'lab_B',  # Client 2\n",
    "#     'lab_C',  # Client 3\n",
    "#     'lab_D',  # Client 4\n",
    "#     'lab_E',  # Client 5\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################# Microbiome Data ####################\n",
    "# # First define the basefolder where all files are located\n",
    "# base_dir = os.path.join(\"..\")\n",
    "# # Go back to the git repos root dir\n",
    "# base_dir = os.path.join(base_dir, \"evaluation_data\", \"microbiome\", \"before\")\n",
    "\n",
    "# # List of cohort names\n",
    "# cohort_names = [\n",
    "#     'PRJEB27928',  # Client 1 (Coordinator)\n",
    "#     'PRJEB6070',   # Client 2\n",
    "#     'PRJNA429097', # Client 3\n",
    "#     'PRJEB10878',  # Client 4\n",
    "#     'PRJNA731589', # Client 5\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################### Simulation Data ###################\n",
    "\n",
    "# # First define the basefolder where all files are located\n",
    "# base_dir = os.path.join(\"..\")\n",
    "# # Go back to the git repos root dir\n",
    "# # base_dir = os.path.join(base_dir, \"evaluation_data\", \"simulated\", \"balanced\", \"before\")\n",
    "# # base_dir = os.path.join(base_dir, \"evaluation_data\", \"simulated\", \"mild_imbalanced\", \"before\")\n",
    "# # base_dir = os.path.join(base_dir, \"evaluation_data\", \"simulated\", \"strong_imbalanced\", \"before\")\n",
    "\n",
    "# # List of cohort names\n",
    "# cohort_names = [\n",
    "#     'lab1',  # Client 1 (Coordinator)\n",
    "#     'lab2',  # Client 2\n",
    "#     'lab3',  # Client 3\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize clientWrappers list\n",
    "clientWrappers: List[ClientWrapper] = []\n",
    "\n",
    "# Iterate over cohort names and create ClientWrapper instances\n",
    "for i, cohortname in enumerate(cohort_names):\n",
    "    clientWrappers.append(ClientWrapper(\n",
    "        id=cohortname,\n",
    "        input_folder=os.path.join(base_dir, cohortname),\n",
    "        coordinator=(i == 0)  # Set the first client as coordinator\n",
    "    ))\n",
    "\n",
    "# Double check that we only have one coordinator\n",
    "_check_consistency_clientwrappers(clientWrappers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "###                                  INFO                                  ###\n",
    "### The following code blocks run the simulation. They are divided into    ###\n",
    "### multiple logical blocks to ease the use                                ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the following config:\n",
      "{'flimmaBatchCorrection': {'min_samples': 2, 'data_filename': 'intensities.tsv', 'separator': '\\t', 'covariates': ['A'], 'design_filename': 'design.tsv', 'index_col': 'rowname', 'expression_file_flag': True}}\n",
      "Opening dataset ../evaluation_data/simulated/strong_imbalanced/before/lab1/intensities.tsv\n",
      "Shape of rawdata(expr_file): (6000, 40)\n",
      "finished loading data, shape of data: (6000, 40), num_features: 6000, num_samples: 40\n",
      "Got the following config:\n",
      "{'flimmaBatchCorrection': {'min_samples': 2, 'data_filename': 'intensities.tsv', 'separator': '\\t', 'covariates': ['A'], 'design_filename': 'design.tsv', 'index_col': 'rowname', 'expression_file_flag': True}}\n",
      "Opening dataset ../evaluation_data/simulated/strong_imbalanced/before/lab2/intensities.tsv\n",
      "Shape of rawdata(expr_file): (6000, 80)\n",
      "finished loading data, shape of data: (6000, 80), num_features: 6000, num_samples: 80\n",
      "Got the following config:\n",
      "{'flimmaBatchCorrection': {'min_samples': 2, 'data_filename': 'intensities.tsv', 'separator': '\\t', 'covariates': ['A'], 'design_filename': 'design.tsv', 'index_col': 'rowname', 'expression_file_flag': True}}\n",
      "Opening dataset ../evaluation_data/simulated/strong_imbalanced/before/lab3/intensities.tsv\n",
      "Shape of rawdata(expr_file): (6000, 480)\n",
      "finished loading data, shape of data: (6000, 480), num_features: 6000, num_samples: 480\n"
     ]
    }
   ],
   "source": [
    "### SIMULATION: all: initial ###\n",
    "### Initial reading of the input folder\n",
    "\n",
    "send_features_variables = list()\n",
    "for clientWrapper in clientWrappers:\n",
    "    # define the client class\n",
    "    cohort_name = clientWrapper.id\n",
    "    client = Client()\n",
    "    client.config_based_init(clientname = cohort_name,\n",
    "                             input_folder = clientWrapper.input_folder,\n",
    "                             use_hashing = False)\n",
    "    clientWrapper.client_class = client\n",
    "    send_features_variables.append((cohort_name,   # for mask creation - to track the cohort\n",
    "                                    list(client.hash2feature.keys()), \n",
    "                                    list(client.hash2variable.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SIMULATION: Coordinator: global_feature_selection ###\n",
    "### Aggregate the features and variables\n",
    "\n",
    "# obtain and safe common genes and indices of design matrix\n",
    "# wait for each client to send the list of genes they have\n",
    "# also memo the feature presence matrix and feature_to_cohorts\n",
    "\n",
    "broadcast_features_variables = tuple()\n",
    "for clientWrapper in clientWrappers:\n",
    "    if clientWrapper.is_coordinator:\n",
    "        global_feature_names, global_variables, feature_presence_matrix, cohorts_order = \\\n",
    "            select_common_features_variables(\n",
    "                lists_of_features_and_variables=send_features_variables,\n",
    "                min_clients=1      # minimum number of clients that need to have the feature\n",
    "            )\n",
    "        # memo the feature presence matrix and feature_to_cohorts\n",
    "        broadcast_features_variables = global_feature_names, global_variables\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SIMULATION: Coordinator: feature presence matrix ###\n",
    "### Compute the feature presence matrix that will be used for the mask creation\n",
    "\n",
    "for clientWrapper in clientWrappers:\n",
    "    if clientWrapper.is_coordinator:\n",
    "        all_client_names = [cw.id for cw in clientWrappers]\n",
    "        feature_presence_matrix = reorder_matrix(feature_presence_matrix, \n",
    "                                          all_client_names, \n",
    "                                          cohorts_order)\n",
    "        # memo the feature presence matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client lab1: Inputs validated.\n",
      "feature names: 6000\n",
      "global features: 6000\n",
      "Extra local features: 0\n",
      "Extra global features: 0\n",
      "Adding 0 extra global features\n",
      "Got 6000 global features and 6000 features in the data matrix\n",
      "Before reindexing got this data: (6000, 40)\n",
      "After reindexing got this data: (6000, 40)\n",
      "design was finally created:        intercept  A  lab1  lab2\n",
      "file                           \n",
      "s.2          1.0  1     1     0\n",
      "s.8          1.0  1     1     0\n",
      "s.43         1.0  1     1     0\n",
      "s.61         1.0  1     1     0\n",
      "s.66         1.0  1     1     0\n",
      "s.68         1.0  1     1     0\n",
      "s.70         1.0  1     1     0\n",
      "s.71         1.0  1     1     0\n",
      "s.72         1.0  1     1     0\n",
      "s.79         1.0  1     1     0\n",
      "s.116        1.0  1     1     0\n",
      "s.130        1.0  1     1     0\n",
      "s.145        1.0  1     1     0\n",
      "s.148        1.0  1     1     0\n",
      "s.149        1.0  1     1     0\n",
      "s.150        1.0  1     1     0\n",
      "s.174        1.0  1     1     0\n",
      "s.191        1.0  1     1     0\n",
      "s.197        1.0  1     1     0\n",
      "s.209        1.0  1     1     0\n",
      "s.214        1.0  1     1     0\n",
      "s.225        1.0  1     1     0\n",
      "s.240        1.0  1     1     0\n",
      "s.276        1.0  1     1     0\n",
      "s.277        1.0  1     1     0\n",
      "s.279        1.0  1     1     0\n",
      "s.282        1.0  1     1     0\n",
      "s.299        1.0  1     1     0\n",
      "s.308        1.0  1     1     0\n",
      "s.318        1.0  1     1     0\n",
      "s.323        1.0  1     1     0\n",
      "s.325        1.0  1     1     0\n",
      "s.350        1.0  0     1     0\n",
      "s.391        1.0  0     1     0\n",
      "s.402        1.0  0     1     0\n",
      "s.456        1.0  0     1     0\n",
      "s.460        1.0  0     1     0\n",
      "s.511        1.0  0     1     0\n",
      "s.525        1.0  0     1     0\n",
      "s.557        1.0  0     1     0\n",
      "shape of design: (40, 4)\n",
      "Client lab2: Inputs validated.\n",
      "feature names: 6000\n",
      "global features: 6000\n",
      "Extra local features: 0\n",
      "Extra global features: 0\n",
      "Adding 0 extra global features\n",
      "Got 6000 global features and 6000 features in the data matrix\n",
      "Before reindexing got this data: (6000, 80)\n",
      "After reindexing got this data: (6000, 80)\n",
      "design was finally created:        intercept  A  lab1  lab2\n",
      "file                           \n",
      "s.3          1.0  1     0     1\n",
      "s.31         1.0  1     0     1\n",
      "s.35         1.0  1     0     1\n",
      "s.52         1.0  1     0     1\n",
      "s.57         1.0  1     0     1\n",
      "...          ... ..   ...   ...\n",
      "s.591        1.0  0     0     1\n",
      "s.594        1.0  0     0     1\n",
      "s.596        1.0  0     0     1\n",
      "s.599        1.0  0     0     1\n",
      "s.600        1.0  0     0     1\n",
      "\n",
      "[80 rows x 4 columns]\n",
      "shape of design: (80, 4)\n",
      "Client lab3: Inputs validated.\n",
      "feature names: 6000\n",
      "global features: 6000\n",
      "Extra local features: 0\n",
      "Extra global features: 0\n",
      "Adding 0 extra global features\n",
      "Got 6000 global features and 6000 features in the data matrix\n",
      "Before reindexing got this data: (6000, 480)\n",
      "After reindexing got this data: (6000, 480)\n",
      "design was finally created:        intercept  A  lab1  lab2\n",
      "file                           \n",
      "s.1          1.0  1    -1    -1\n",
      "s.4          1.0  1    -1    -1\n",
      "s.5          1.0  1    -1    -1\n",
      "s.6          1.0  1    -1    -1\n",
      "s.7          1.0  1    -1    -1\n",
      "...          ... ..   ...   ...\n",
      "s.592        1.0  0    -1    -1\n",
      "s.593        1.0  0    -1    -1\n",
      "s.595        1.0  0    -1    -1\n",
      "s.597        1.0  0    -1    -1\n",
      "s.598        1.0  0    -1    -1\n",
      "\n",
      "[480 rows x 4 columns]\n",
      "shape of design: (480, 4)\n"
     ]
    }
   ],
   "source": [
    "### SIMULATION: All: validate ###\n",
    "### Expand data to fullfill the global format. Also performs consistency checks\n",
    "\n",
    "for clientWrapper in clientWrappers:\n",
    "    global_feauture_names_hashed, global_variables_hashed = \\\n",
    "        broadcast_features_variables\n",
    "    client = clientWrapper.client_class\n",
    "    client.validate_inputs(global_variables_hashed)\n",
    "    client.set_data(global_feauture_names_hashed)\n",
    "    # get all client names to generate design matrix\n",
    "    all_client_names = [cw.id for cw in clientWrappers]\n",
    "    err = client.create_design(all_client_names[:-1])\n",
    "    if err:\n",
    "        raise ValueError(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulatuion: Coordinator: create design mask based on feature presence matrix ###\n",
    "### Create the mask for the design matrix based on the feature presence matrix\n",
    "### that will be used for the beta computation\n",
    "for clientWrapper in clientWrappers:\n",
    "    if clientWrapper.is_coordinator:\n",
    "        client = clientWrapper.client_class\n",
    "\n",
    "        n=len(client.feature_names)\n",
    "        k=client.design.shape[1]\n",
    "\n",
    "        global_mask = create_beta_mask(feature_presence_matrix, n, k)\n",
    "        # memo the global mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SIMULATION: All: prepare for compute_XtX_XtY ###\n",
    "\n",
    "for clientWrapper in clientWrappers:\n",
    "    client = clientWrapper.client_class\n",
    "    client.sample_names = client.design.index.values\n",
    "\n",
    "    # Error check if the design index and the data index are the same\n",
    "    # we check by comparing the sorted indexes\n",
    "    client._check_consistency_designfile()\n",
    "\n",
    "    # Extract only relevant (the global) features and samples\n",
    "    client.data = client.data.loc[client.feature_names, client.sample_names]\n",
    "    client.n_samples = len(client.sample_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final vectors to be sent: XtX shape: (6000, 4, 4), XtY shape: (6000, 4)\n",
      "final vectors to be sent: XtX shape: (6000, 4, 4), XtY shape: (6000, 4)\n",
      "final vectors to be sent: XtX shape: (6000, 4, 4), XtY shape: (6000, 4)\n"
     ]
    }
   ],
   "source": [
    "### SIMULATION: All: compute_XtX_XtY ###\n",
    "### Compute XtX and XtY and share it\n",
    "send_XtX_XtY_list: List[List[np.ndarray]] = list()\n",
    "for clientWrapper in clientWrappers:\n",
    "    client = clientWrapper.client_class\n",
    "\n",
    "    # compute XtX and XtY\n",
    "    XtX, XtY, err = client.compute_XtX_XtY()\n",
    "    if err != None:\n",
    "        raise ValueError(err)\n",
    "\n",
    "    # send XtX and XtY\n",
    "    send_XtX_XtY_list.append([XtX, XtY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Shape of beta: (6000, 4)\n",
      "INFO: Number of pseudo inverses: 0\n"
     ]
    }
   ],
   "source": [
    "### SIMULATION: Coordinator: compute_beta\n",
    "### Compute the beta values and broadcast them to the others\n",
    "broadcast_betas = None # np.ndarray of shape num_features x design_columns\n",
    "\n",
    "for clientWrapper in clientWrappers:\n",
    "    if clientWrapper.is_coordinator:\n",
    "        client = clientWrapper.client_class\n",
    "        beta = compute_beta(XtX_XtY_list=send_XtX_XtY_list,\n",
    "                            n=len(client.feature_names),\n",
    "                            k=client.design.shape[1],\n",
    "                            global_mask=global_mask)\n",
    "\n",
    "        # send beta to clients so they can correct their data\n",
    "        broadcast_betas = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start remove_batch_effects\n",
      "Shape of data: (6000, 40)\n",
      "Shape of beta:  (6000, 4)\n",
      "Beta_reduced contains 0 Nan values\n",
      "Shape of corrected data after correction: (6000, 40)\n",
      "index is Index(['prt1', 'prt10', 'prt100', 'prt1000', 'prt1001', 'prt1002', 'prt1003',\n",
      "       'prt1004', 'prt1005', 'prt1006',\n",
      "       ...\n",
      "       'prt990', 'prt991', 'prt992', 'prt993', 'prt994', 'prt995', 'prt996',\n",
      "       'prt997', 'prt998', 'prt999'],\n",
      "      dtype='object', name='rowname', length=6000)\n",
      "Amount of index found in hash2feature: 6000/6000\n",
      "After renaming got this data_corrected:               s.2       s.8      s.43      s.61      s.66      s.68      s.70  \\\n",
      "rowname                                                                         \n",
      "prt1     4.118892  1.292223  3.116327  4.140534  3.771757  2.689642  3.530103   \n",
      "prt10         NaN  1.501808  1.796556  2.535661  0.946897  2.585099  6.276444   \n",
      "prt100   2.127191  1.175886  3.562082  0.208046  2.278212  1.422361  4.612191   \n",
      "prt1000  2.396597  1.142557  1.532441 -0.042075  0.566987 -0.154488  0.880776   \n",
      "prt1001       NaN -3.019587 -3.997545       NaN       NaN       NaN       NaN   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "prt995  -1.094704  1.547244 -1.274515 -0.643763  1.034905 -0.359000  0.353578   \n",
      "prt996   0.733146  1.191644 -0.027057       NaN  0.408488  1.371449  2.613480   \n",
      "prt997   0.162717  2.929573  1.479036  3.507268  3.490206  0.713401  0.433792   \n",
      "prt998   2.105225  1.973018  0.827786  1.322269  1.218094  1.966791  1.633763   \n",
      "prt999   0.274294 -0.673372  0.589555  0.523735  1.621538  2.519452  3.700653   \n",
      "\n",
      "             s.71      s.72      s.79  ...     s.323     s.325     s.350  \\\n",
      "rowname                                ...                                 \n",
      "prt1     2.578239  0.746875  2.544026  ...  4.349287       NaN  3.700623   \n",
      "prt10    1.520561  3.467431  4.055775  ...       NaN  4.333232  1.687077   \n",
      "prt100   2.647787  0.617554  4.477984  ...  4.347018 -2.727530  0.844458   \n",
      "prt1000  0.942994  1.524011 -0.911357  ...  1.474743  0.705393       NaN   \n",
      "prt1001       NaN -2.310718 -3.409496  ... -3.717839       NaN -1.416164   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "prt995   1.418200  0.305260  2.954261  ...  4.557448 -2.078763 -5.304187   \n",
      "prt996   1.538901  0.863370 -0.725253  ... -0.119652       NaN -0.573057   \n",
      "prt997   2.751512  2.393123  3.497791  ...       NaN -1.536002  6.096837   \n",
      "prt998   2.214404  0.798465  1.545582  ...  1.987470  0.479190  1.816892   \n",
      "prt999   5.440556  1.947592 -2.599164  ...  2.191432  3.761025 -0.070740   \n",
      "\n",
      "            s.391     s.402     s.456     s.460     s.511     s.525     s.557  \n",
      "rowname                                                                        \n",
      "prt1     0.409616  4.283170  2.107137  4.668622  4.064353  2.437916  2.773573  \n",
      "prt10    2.368099  2.654740 -0.892597  3.450706  1.406627  0.677751  1.939488  \n",
      "prt100   0.807616 -1.868588  1.451785  1.952210  2.271625  1.595974 -2.249851  \n",
      "prt1000  1.812695 -0.955840 -0.099585  0.240302  1.636995  3.125518       NaN  \n",
      "prt1001       NaN -3.672300 -2.608867 -1.855613 -1.349241       NaN -1.547152  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "prt995   3.796548 -1.479299       NaN -0.644614  1.547562 -2.474142  0.684795  \n",
      "prt996   1.453550 -0.832412 -1.090529 -0.363292  1.136070       NaN  0.410856  \n",
      "prt997   2.237595  5.464435       NaN  3.078966  0.387648  5.517329  4.416061  \n",
      "prt998   0.429724  0.592445  1.255402  2.682516  1.707374  0.734198  1.426433  \n",
      "prt999   2.892320 -1.470152 -1.367653  1.813466  0.554957  2.600532       NaN  \n",
      "\n",
      "[6000 rows x 40 columns]\n",
      "remove batch final corrected data shape: (6000, 40)\n",
      "DEBUG: Shape of corrected data: (6000, 40)\n",
      "start remove_batch_effects\n",
      "Shape of data: (6000, 80)\n",
      "Shape of beta:  (6000, 4)\n",
      "Beta_reduced contains 0 Nan values\n",
      "Shape of corrected data after correction: (6000, 80)\n",
      "index is Index(['prt1', 'prt10', 'prt100', 'prt1000', 'prt1001', 'prt1002', 'prt1003',\n",
      "       'prt1004', 'prt1005', 'prt1006',\n",
      "       ...\n",
      "       'prt990', 'prt991', 'prt992', 'prt993', 'prt994', 'prt995', 'prt996',\n",
      "       'prt997', 'prt998', 'prt999'],\n",
      "      dtype='object', name='rowname', length=6000)\n",
      "Amount of index found in hash2feature: 6000/6000\n",
      "After renaming got this data_corrected:               s.3      s.31      s.35      s.52      s.57      s.83     s.103  \\\n",
      "rowname                                                                         \n",
      "prt1     3.478657  2.061768  8.191715  5.783844  2.493683  3.264129  2.552611   \n",
      "prt10         NaN  2.031092  0.996766  2.470613  3.701025  1.782338  0.009218   \n",
      "prt100   1.952802 -0.288590  1.269154       NaN  0.058053  3.284571  2.319458   \n",
      "prt1000  0.249463 -0.353212 -1.059987  0.036519  3.282405 -0.785470 -0.665350   \n",
      "prt1001 -0.627293       NaN -2.860948 -2.710733 -4.552713 -2.355828 -0.886855   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "prt995   3.066048 -3.204748  0.330007  2.456337 -2.366225 -4.373783  2.999877   \n",
      "prt996  -0.646028  1.225748  0.859296       NaN  0.782928  1.586538       NaN   \n",
      "prt997   6.838367  4.584719  3.616790  4.819005  1.286956  0.460253       NaN   \n",
      "prt998   1.551332       NaN  1.868468  2.315831  2.405788  1.046199       NaN   \n",
      "prt999   0.881626  1.158725  1.266561  0.529368  0.478750  3.419942  2.165373   \n",
      "\n",
      "            s.106     s.140     s.151  ...     s.572     s.582     s.583  \\\n",
      "rowname                                ...                                 \n",
      "prt1     4.616790  3.417973  3.578791  ...  1.520256  3.004886 -0.916072   \n",
      "prt10    5.090315  2.669092  0.931181  ...  1.225170 -0.233088  2.606918   \n",
      "prt100   0.683523  3.430338       NaN  ...  1.460863  0.419754  4.026741   \n",
      "prt1000 -3.372355 -0.982308  0.140473  ... -1.379737  1.210778  1.070239   \n",
      "prt1001 -0.918007 -2.022656 -0.478319  ...       NaN       NaN       NaN   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "prt995  -1.524681  0.135402       NaN  ...       NaN -0.706801       NaN   \n",
      "prt996   0.994830       NaN  0.934443  ...  0.003865  0.207310  1.513948   \n",
      "prt997        NaN -0.603312  1.097861  ...  1.895637  0.354278  0.086673   \n",
      "prt998   1.966255  1.824033  2.206153  ...  2.225922  0.878966  1.204270   \n",
      "prt999  -0.979235  1.931793  3.025564  ... -0.373776  3.091042  1.342274   \n",
      "\n",
      "            s.587     s.588     s.591     s.594     s.596     s.599     s.600  \n",
      "rowname                                                                        \n",
      "prt1     2.614171  2.771396  1.769058  1.230378  1.529486  2.543909  2.645514  \n",
      "prt10         NaN  0.462589  1.615356       NaN  0.416054       NaN  0.865730  \n",
      "prt100        NaN  4.047866  2.318852  2.249215  2.982594  6.236580  1.473043  \n",
      "prt1000 -1.677551       NaN -1.269174 -0.602506  2.012464 -2.197358  0.409771  \n",
      "prt1001 -2.457751       NaN -4.189383 -2.153882 -2.872131 -2.150457 -1.739035  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "prt995   5.478304  0.837783  0.332900  3.135054 -0.809815       NaN  0.583533  \n",
      "prt996        NaN -0.235348  1.489856 -1.235220  0.443752  1.106949  1.483320  \n",
      "prt997   1.461891  0.775822  1.764956  3.491901  4.767660  3.052627  2.220870  \n",
      "prt998   1.820438       NaN  1.581467  1.919644  1.040911       NaN  1.258902  \n",
      "prt999        NaN  0.061407  3.080064  2.750679  0.331139 -1.109048  3.474325  \n",
      "\n",
      "[6000 rows x 80 columns]\n",
      "remove batch final corrected data shape: (6000, 80)\n",
      "DEBUG: Shape of corrected data: (6000, 80)\n",
      "start remove_batch_effects\n",
      "Shape of data: (6000, 480)\n",
      "Shape of beta:  (6000, 4)\n",
      "Beta_reduced contains 0 Nan values\n",
      "Shape of corrected data after correction: (6000, 480)\n",
      "index is Index(['prt1', 'prt10', 'prt100', 'prt1000', 'prt1001', 'prt1002', 'prt1003',\n",
      "       'prt1004', 'prt1005', 'prt1006',\n",
      "       ...\n",
      "       'prt990', 'prt991', 'prt992', 'prt993', 'prt994', 'prt995', 'prt996',\n",
      "       'prt997', 'prt998', 'prt999'],\n",
      "      dtype='object', name='rowname', length=6000)\n",
      "Amount of index found in hash2feature: 6000/6000\n",
      "After renaming got this data_corrected:               s.1       s.4       s.5       s.6       s.7       s.9      s.10  \\\n",
      "rowname                                                                         \n",
      "prt1          NaN  3.988309  3.699662       NaN       NaN  5.786739  3.563079   \n",
      "prt10         NaN  2.131657  2.810569  2.827868  2.838388  4.179579 -0.273672   \n",
      "prt100   1.534300 -0.103018       NaN  0.772855  2.496830  2.913312  1.996129   \n",
      "prt1000       NaN -0.730383  1.233654  4.972126 -0.285944  1.988320 -0.296994   \n",
      "prt1001 -2.557925 -2.365028 -3.616423 -3.389868 -0.597487       NaN -2.093015   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "prt995        NaN -0.222854 -0.887779 -1.581900  1.979426 -0.787426  0.612056   \n",
      "prt996  -0.126581 -0.001654       NaN       NaN       NaN  0.743654 -0.241466   \n",
      "prt997   3.283506  0.326023  2.119663  0.309011  4.431390  0.568807  2.176833   \n",
      "prt998   1.615632  1.859240  1.730007  0.950608  1.552486  1.570178  0.772940   \n",
      "prt999        NaN  1.526975  1.021997  2.051455  1.928723  0.699562  0.905451   \n",
      "\n",
      "             s.11      s.12      s.13  ...     s.584     s.585     s.586  \\\n",
      "rowname                                ...                                 \n",
      "prt1     4.544273  4.656176  3.355858  ...  2.473861       NaN  1.475206   \n",
      "prt10    2.505392       NaN  2.820731  ... -0.342935  1.062449  1.187520   \n",
      "prt100   1.239989  1.491312  3.949909  ...  2.629487 -0.686909 -0.206550   \n",
      "prt1000 -0.395741 -0.618322 -0.900957  ...       NaN -1.045482  2.476713   \n",
      "prt1001 -3.313143       NaN       NaN  ...       NaN -2.367601 -3.650370   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "prt995        NaN -0.511474  1.802268  ...  0.334829  2.064030 -1.853599   \n",
      "prt996   0.980054 -0.005825  0.555022  ...  0.642365       NaN  0.644111   \n",
      "prt997   2.765717  2.530623  3.903576  ... -0.062390  3.717022  2.461186   \n",
      "prt998   0.722844  2.127061  1.909707  ...  1.801566       NaN  2.058877   \n",
      "prt999        NaN  0.142932  0.305827  ...       NaN       NaN -0.032802   \n",
      "\n",
      "            s.589     s.590     s.592     s.593     s.595     s.597     s.598  \n",
      "rowname                                                                        \n",
      "prt1          NaN  3.486847  2.464476       NaN  1.544333  4.326034  4.565810  \n",
      "prt10    2.644110 -0.198841       NaN  0.379056  0.808016 -0.249406  2.285561  \n",
      "prt100   1.750060 -0.144181 -2.462053  3.426894       NaN       NaN  3.042385  \n",
      "prt1000 -1.112484       NaN -1.096967 -2.384282  3.962920  1.730243       NaN  \n",
      "prt1001       NaN -1.100425 -1.893794 -2.497094       NaN -4.843127 -0.966103  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "prt995   1.567929 -0.038738       NaN       NaN -5.360457  0.389112       NaN  \n",
      "prt996   2.717400 -0.307225  0.713458       NaN       NaN -0.053937 -0.057498  \n",
      "prt997   2.340744  2.966210 -0.084603  3.308446  2.893353  2.977000  1.560844  \n",
      "prt998   0.942200       NaN  2.353003  2.149268  1.955602  1.996651  1.543729  \n",
      "prt999  -1.247192 -0.348277  3.237128  0.130312 -0.467979       NaN  0.660774  \n",
      "\n",
      "[6000 rows x 480 columns]\n",
      "remove batch final corrected data shape: (6000, 480)\n",
      "DEBUG: Shape of corrected data: (6000, 480)\n"
     ]
    }
   ],
   "source": [
    "### SIMULATION: All: include_correction\n",
    "### Corrects the individual data\n",
    "for clientWrapper in clientWrappers:\n",
    "    client = clientWrapper.client_class\n",
    "\n",
    "    # remove the batch effects in own data and safe the results\n",
    "    client.remove_batch_effects(beta)\n",
    "    print(f\"DEBUG: Shape of corrected data: {client.data_corrected.shape}\")\n",
    "    # As this is a simulation we don't save the corrected data to csv, instead\n",
    "    # we save it as a variable to the clientwrapper\n",
    "    clientWrapper.data_corrected = client.data_corrected\n",
    "    # client.data_corrected.to_csv(os.path.join(os.getcwd(), \"mnt\", \"output\", \"only_batch_corrected_data.csv\"),\n",
    "    #                                 sep=self.load(\"separator\"))\n",
    "    # client.data_corrected_and_raw.to_csv(os.path.join(os.getcwd(), \"mnt\", \"output\", \"all_data.csv\"),\n",
    "    #                              sep=self.load(\"separator\"))\n",
    "    # with open(os.path.join(os.getcwd(), \"mnt\", \"output\", \"report.txt\"), \"w\") as f:\n",
    "    #     f.write(client.report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "###                                  INFO                                  ###\n",
    "###                            SIMULATION IS DONE                          ###\n",
    "### The simulation is done. The corrected data is saved in the             ###\n",
    "### clientWrapper instances. Now we analyse the data by comparing to the   ###\n",
    "### calculated centralized corrected data.                                 ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_df, intersect_features = _concat_federated_results(clientWrappers, samples_in_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE THE RESULTS ###\n",
    "# Microarray data\n",
    "federated_df.to_csv(os.path.join(\"..\", \"evaluation_data\", \"microarray\", \"after\", \"FedSim_corrected_data.tsv\"), sep=\"\\t\")\n",
    "\n",
    "# # Proteomics data\n",
    "# federated_df.to_csv(os.path.join(\"..\", \"evaluation_data\", \"proteomics\", \"after\", \"FedSim_corrected_data.tsv\"), sep=\"\\t\")\n",
    "\n",
    "# Microbiome data\n",
    "# federated_df.to_csv(os.path.join(\"..\", \"evaluation_data\", \"microbiome\", \"after\", \"FedSim_corrected_data.tsv\"), sep=\"\\t\")\n",
    "\n",
    "# Simulation data\n",
    "# federated_df.to_csv(os.path.join(\"..\", \"evaluation_data\", \"simulated\", \"balanced\", \"after\", \"FedSim_corrected_data.tsv\"), sep=\"\\t\")\n",
    "# federated_df.to_csv(os.path.join(\"..\", \"evaluation_data\", \"simulated\", \"mild_imbalanced\", \"after\", \"FedSim_corrected_data.tsv\"), sep=\"\\t\")\n",
    "# federated_df.to_csv(os.path.join(\"..\", \"evaluation_data\", \"simulated\", \"strong_imbalanced\", \"after\", \"FedSim_corrected_data.tsv\"), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________Analysing: microarray_________________________\n",
      "Max difference: 8.171241461241152e-14\n",
      "Mean difference: 4.357000735613189e-15\n",
      "Max diff at position: GSM1701030\n",
      "Max difference in intersect: 8.171241461241152e-14\n",
      "Mean difference in intersect: 4.515621419262236e-15\n",
      "Max diff at position in intersect: GSM1701030\n"
     ]
    }
   ],
   "source": [
    "### Concat the federated data and read in the centralized data ###\n",
    "central_df_path = os.path.join(os.path.dirname(base_dir), \"after\", \"central_corrected_UNION.tsv\")\n",
    "central_df = pd.read_csv(central_df_path, sep=\"\\t\", index_col=0)\n",
    "_compare_central_federated_dfs(\"microarray\", central_df, federated_df, intersect_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________Analysing: proteomic data_________________________\n",
      "Max difference: 1.9184653865522705e-13\n",
      "Mean difference: 3.1758692034102934e-14\n",
      "Max diff at position: Clinspect_E_coli_A_S42_Slot1-21_1_8670\n",
      "Max difference in intersect: 1.1368683772161603e-13\n",
      "Mean difference in intersect: 3.338152465379177e-14\n",
      "Max diff at position in intersect: Clinspect_E_coli_A_S42_Slot1-21_1_8670\n"
     ]
    }
   ],
   "source": [
    "### Concat the federated data and read in the centralized data ###\n",
    "central_df_path = os.path.join(os.path.dirname(os.path.dirname(base_dir)), \"proteomics\", \"after\", \"intensities_log_Rcorrected_UNION.tsv\")\n",
    "central_df = pd.read_csv(central_df_path, sep=\"\\t\", index_col=0)\n",
    "_compare_central_federated_dfs(\"proteomic data\", central_df, federated_df, intersect_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
